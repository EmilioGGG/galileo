{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incorporated-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorboard as tb\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bridal-alberta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled compatitility to tf1.x\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "  print(\"Enabled compatitility to tf1.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "liable-swedish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "equipped-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Data a utilizar en el proyecto:\n",
    "\n",
    "data_total = np.load('C:/Users/Gary/Google Drive/Universidad/MAESTRIA/Data Science/Año 1/1. Trimestre I/2. Ciencia de Datos en Python/Tareas/Proyecto Final/proyecto_data/proyecto_training_data.npy')\n",
    "data_total.shape\n",
    "\n",
    "#Se usará el 80% para los \"Datos de entrenamiento\"\n",
    "Parte1 = round(len(data_total)*0.8)\n",
    "data_entrenamiento = data_total[0:int(data_total.shape[0]*.8)+1]\n",
    "\n",
    "#Se usará el 20% para \"Datos de validación y pruebas\"\n",
    "Parte2 = round(len(data_total)*0.2)\n",
    "data_validacion = data_total[int(data_total.shape[0]*.8)+1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "velvet-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(y_real,y_aprox):\n",
    "  return 1/2*tf.reduce_mean(tf.math.square(y_real - y_aprox) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reported-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_entrenamiento[:,3]\n",
    "y = data_entrenamiento[:,0]\n",
    "tamaño_muestra = data_entrenamiento.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "isolated-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModeloLineal:\n",
    "  def __init__(self):\n",
    "    tf.reset_default_graph()\n",
    "    self.mb = tf.get_variable(\"PENDIENTE_INTERC\",dtype=tf.float64,shape=[2,1],initializer=tf.zeros_initializer())\n",
    "    self.error = tf.get_variable(\"ERROR_VAL\",dtype=tf.float64,shape=[1],initializer=tf.zeros_initializer())\n",
    "    \n",
    "  def __call__(self,x):\n",
    "    x = tf.concat([x,tf.ones_like(x,name=\"XVec_1\")], axis=1,name=\"XAdd_1\")  \n",
    "    return tf.matmul(x,self.mb,name=\"Prediccion\")\n",
    "\n",
    "  def actualizar(self,x,y,learning_rate):\n",
    "    prediccion = self(x)\n",
    "    error = 1/2 * tf.math.reduce_mean(tf.math.square(y - prediccion,name=\"Error_Error\"),axis=0,name=\"Error_Med\") \n",
    "    gradiente = tf.gradients(error,self.mb, name=\"Grad\")  \n",
    "    actual_error = tf.assign(self.error, error)\n",
    "    actual_param = tf.assign(self.mb,self.mb - tf.multiply(gradiente,learning_rate)[0],name=\"Actualizacion_Param\")\n",
    "\n",
    "    return actual_param,actual_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fundamental-future",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[208500.]\n",
      " [181500.]\n",
      " [223500.]\n",
      " ...\n",
      " [245350.]\n",
      " [173000.]\n",
      " [235000.]]\n"
     ]
    }
   ],
   "source": [
    "#Modificando nuestra data de entrenamiento para acoplarla\n",
    "#y definiendo los hiper parametros\n",
    "Data_X = data_entrenamiento[:,1].reshape([-1,1])\n",
    "Data_Y = data_entrenamiento[:,0].reshape([-1,1])\n",
    "\n",
    "#Hyper-Parametros\n",
    "lr = 0.00001\n",
    "bs = 350\n",
    "ep = 350\n",
    "\n",
    "print(Data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "stretch-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion modelo regresion lineal\n",
    "\n",
    "def ModeloRegresionLineal(X,Y,learning_rate,batch_size,epochs):  \n",
    "    #plt.scatter(X,Y)\n",
    "\n",
    "    modelo = ModeloLineal()\n",
    "    tamaño_muestra = X.shape[0]\n",
    "\n",
    "    total_iteraciones =  int(tamaño_muestra/batch_size)\n",
    "\n",
    "    #Creacion de tensores a utilizar\n",
    "    tensor_x = tf.placeholder(tf.float64,[None,1],\"tensor_x\")\n",
    "    tensor_y = tf.placeholder(tf.float64,[None,1],\"tensor_y\")\n",
    "\n",
    "    #Creacion Modelo\n",
    "    prediccion = modelo(tensor_x)\n",
    "    actualizacion_parametros = modelo.actualizar(tensor_x,tensor_y,learning_rate)\n",
    "\n",
    "    #Inicio de programancion de grafo\n",
    "    with tf.train.MonitoredSession() as session:\n",
    "        tf.reset_default_graph()   \n",
    "        log_dir = \"logs/Entrenamiento/\"+\"BS-\"+str(batch_size)+\"_\"+\"LR-\"+str(learning_rate)+\"_\"+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        Grafo = tf.summary.FileWriter(log_dir, session.graph)\n",
    "\n",
    "\n",
    "        for epoch in range(epochs):    \n",
    "            for i in range(total_iteraciones):          \n",
    "                muestra_inicio = i*batch_size\n",
    "                muestra_fin = muestra_inicio + batch_size\n",
    "\n",
    "                x_mb =  np.array(X[muestra_inicio:muestra_fin])\n",
    "                y_mb = np.array(Y[muestra_inicio:muestra_fin])\n",
    "                feed_dict = {tensor_x:x_mb, tensor_y:y_mb}\n",
    "                _,mb,e = session.run([actualizacion_parametros,modelo.mb,modelo.error],feed_dict=feed_dict)            \n",
    "                summary = tf.Summary(value=[tf.Summary.Value(tag=\"Error\", simple_value=e[0])])\n",
    "                Grafo.add_summary(summary, epoch)\n",
    "\n",
    "            feed_dict = {tensor_x:X, tensor_y:Y}\n",
    "        PendienteInter_final = session.run([modelo.mb],feed_dict=feed_dict)\n",
    "        \n",
    "        Grafo.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "behavioral-throat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "ModeloRegresionLineal(Data_X,Data_Y,0.0001,50,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "streaming-confidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "ModeloRegresionLineal(Data_X,Data_Y,0.0001,100,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "macro-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "ModeloRegresionLineal(Data_X,Data_Y,0.0001,200,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "genuine-beijing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "ModeloRegresionLineal(Data_X,Data_Y,0.00001,50,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "headed-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "ModeloRegresionLineal(Data_X,Data_Y,0.00001,100,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aboriginal-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "ModeloRegresionLineal(Data_X,Data_Y,0.00001,200,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "treated-wesley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "ModeloRegresionLineal(Data_X,Data_Y,0.000001,50,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "stuffed-roads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "ModeloRegresionLineal(Data_X,Data_Y,0.000001,100,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "focal-fairy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "ModeloRegresionLineal(Data_X,Data_Y,0.000001,200,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "julian-fiber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1260), started 4:21:22 ago. (Use '!kill 1260' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1fffcaa68f233756\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1fffcaa68f233756\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-launch",
   "metadata": {},
   "source": [
    "## Conclusión: ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-imperial",
   "metadata": {},
   "source": [
    "### Mientras mas bajo sea el learning rate y menor es nuestro tamaño del batch size el error mas alto nos queda el error.\n",
    "### Por lo que lo reconendable es utilizar un modelo con un lr bajo con altas iteracionas para que el entrenamiento del modelo no nos genere mayor error y que tenga un comportamiento predictivo que podamos utilizar. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
